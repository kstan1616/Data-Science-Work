{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import psycopg2 \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import and clean data from MovieLens dataset, prepare for use with imdb API\n",
    "Movie_list = pd.read_csv('Movies.csv', header = 0)\n",
    "\n",
    "def deleteLastspace(title):\n",
    "    return title.rstrip()\n",
    "\n",
    "def deleteThe(title):\n",
    "    title = title.replace(', The ', '')\n",
    "    if title == ', The ':\n",
    "        return title.replace(', The ', '')\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "def deleteA(title):\n",
    "    title = title.replace(', A ', '')\n",
    "    if title == ', A':\n",
    "        return title.replace(', A ', '')\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "def deleteAn(title):\n",
    "    title = title.replace(', An ', '')\n",
    "    if title == ', An ':\n",
    "        return title.replace(', An ', '')\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "def deleteLe(title):\n",
    "    title = title.replace(', Le ', '')\n",
    "    if title == ', Le ':\n",
    "        return title.replace(', Le ', '')\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "def deleteLa(title):\n",
    "    title = title.replace(', La ', '')\n",
    "    if title == ', La ':\n",
    "        return title.replace(', La ', '')\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def deleteEl(title):\n",
    "    title = title.replace(', El ', '')\n",
    "    if title == ', El ':\n",
    "        return title.replace(', El ', '')\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def deleteLes(title):\n",
    "    title = title.replace(', Les', '')\n",
    "    if title == ', Les':\n",
    "        return title.replace(', Les', '')\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "def deleteLastplus(title):\n",
    "    if title[-1] == '+':\n",
    "        return title[0:-1]\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "#extracts year from end of title in parentheses and creates new column with year\n",
    "Movie_list['year'] = Movie_list['title'].str.extract('(\\d\\d\\d\\d)', expand=True)\n",
    "\n",
    "#title that excludes the year\n",
    "Movie_list['title'] = Movie_list['title'].astype(str).str[:-6]\n",
    "\n",
    "#removes everything in parentheses\n",
    "Movie_list['title'] = Movie_list['title'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "\n",
    "#deletes the ', The' at end of title (consider adding other cases into this function)\n",
    "Movie_list['title'] = Movie_list['title'].apply(deleteThe).apply(deleteLes)\\\n",
    "                    .apply(deleteLe).apply(deleteA).apply(deleteAn).apply(deleteLa)\\\n",
    "                    .apply(deleteEl)\n",
    "Movie_list['title'] = Movie_list['title'].apply(deleteLastspace)\n",
    "Movie_list['title'] = Movie_list['title'].str.replace(\" \",\"+\")\n",
    "Movie_list['api'] = Movie_list['title'] + '&y='\n",
    "Movie_list['api-year'] = Movie_list['title'] + '&y=' + Movie_list['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ratings info/pickle for later/building model\n",
    "Data_for_model = pd.read_csv('ratings.csv', header = 0)\n",
    "with open('Data_for_model.pkl', 'w') as picklefile:\n",
    "    pickle.dump(Data_for_model, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resources\n",
    "\n",
    "#http://virendra.me/scraping-imdb-with-python/\n",
    "#https://github.com/richardasaurus/imdb-pie\n",
    "#https://github.com/jameskang410/scraping-netflix\n",
    "#https://www.cinesift.com/#/\n",
    "#http://www.hbo.com/movies/catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#showtime/webscrape data-go back through later to clean up 'links' list\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import HTML\n",
    "from selenium import webdriver\n",
    "links = ['http://www.sho.com/movies/action', 'http://www.sho.com/movies/action/page/2', \\\n",
    "         'http://www.sho.com/movies/action/page/3', 'http://www.sho.com/movies/comedy', \\\n",
    "         'http://www.sho.com/movies/comedy/page/2', 'http://www.sho.com/movies/comedy/page/3', \\\n",
    "         'http://www.sho.com/movies/comedy/page/4', 'http://www.sho.com/movies/comedy/page/5', \\\n",
    "         'http://www.sho.com/movies/documentary', 'http://www.sho.com/movies/documentary/page/2', \\\n",
    "         'http://www.sho.com/movies/drama', 'http://www.sho.com/movies/drama/page/2', \\\n",
    "         'http://www.sho.com/movies/drama/page/3', 'http://www.sho.com/movies/drama/page/4', \\\n",
    "         'http://www.sho.com/movies/drama/page/5', 'http://www.sho.com/movies/drama/page/6', \\\n",
    "         'http://www.sho.com/movies/drama/page/7', 'http://www.sho.com/movies/family', \\\n",
    "         'http://www.sho.com/movies/horror', 'http://www.sho.com/movies/horror/page/2', \\\n",
    "         'http://www.sho.com/movies/music', 'http://www.sho.com/movies/sci-fi-fantasy', \\\n",
    "         'http://www.sho.com/movies/sci-fi-fantasy/page/2', 'http://www.sho.com/movies/suspense', \\\n",
    "         'http://www.sho.com/movies/suspense/page/2', 'http://www.sho.com/movies/suspense/page/3', \\\n",
    "         'http://www.sho.com/movies/suspense/page/4', 'http://www.sho.com/movies/suspense/page/5', \\\n",
    "         'http://www.sho.com/movies/suspense/page/6', 'http://www.sho.com/movies/suspense/page/7']\n",
    "\n",
    "showtime = []\n",
    "\n",
    "#loop through each link, scrape movie titles and append to 'showtime' list\n",
    "for link in links:\n",
    "    show_movie = requests.get(link)\n",
    "    show_soup = BeautifulSoup(show_movie.content, \"lxml\")\n",
    "    titles = show_soup.findAll(class_='movies-gallery__title')\n",
    "    for title in titles:\n",
    "        if title in showtime:\n",
    "            continue\n",
    "        else:\n",
    "            showtime.append([title.text, 'showtime'])\n",
    "\n",
    "#convert into dataframe, in service column populate with 'showtime'\n",
    "showtime_df = pd.DataFrame(data = showtime, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/openpyxl/reader/worksheet.py:322: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#import openpyxl module that imports data from excel files\n",
    "import openpyxl\n",
    "\n",
    "netflix_movies = []\n",
    "\n",
    "#open file, append value for every row in column two and 'netflix' which will be used in \n",
    "#service column in dataframe\n",
    "netflix = openpyxl.load_workbook('NetflixMovies.xlsx')\n",
    "sheet = netflix.get_sheet_by_name('Movies')\n",
    "for x in range(1,4393):\n",
    "    netflix_movies.append([sheet.cell(row=x, column=2).value, 'netflix'])\n",
    "\n",
    "#convert list of lists into dataframe\n",
    "netflix_df = pd.DataFrame(data = netflix_movies, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#repeat process for hulu\n",
    "hulu_movies = []\n",
    "\n",
    "hulu = openpyxl.load_workbook('HuluMovies.xlsx')\n",
    "sheet = hulu.get_sheet_by_name('Sheet1')\n",
    "for x in range(2,1090):\n",
    "    hulu_movies.append([sheet.cell(row=x, column=4).value, 'hulu'])\n",
    "\n",
    "hulu_df = pd.DataFrame(data = hulu_movies, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#amazon\n",
    "amazon_movies = []\n",
    "\n",
    "amazon = openpyxl.load_workbook('AmazonMovies.xlsx')\n",
    "sheet = amazon.get_sheet_by_name('Sheet1')\n",
    "for x in range(2,2537):\n",
    "    sheet.cell(row=x, column=1).value\n",
    "    amazon_movies.append(sheet.cell(row=x, column=1).value)\n",
    "\n",
    "#remove duplicates which have space in front of them\n",
    "Amazon_Movies = []\n",
    "for line in amazon_movies:\n",
    "    if line[0] == \" \":\n",
    "        continue\n",
    "    else:\n",
    "        Amazon_Movies.append([line, 'amazon'])\n",
    "\n",
    "amazon_df = pd.DataFrame(data = Amazon_Movies, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hbo\n",
    "HBO_movies = []\n",
    "\n",
    "HBO = openpyxl.load_workbook('HBOMovies.xlsx')\n",
    "sheet = HBO.get_sheet_by_name('Sheet1')\n",
    "for x in range(2,345):\n",
    "    sheet.cell(row=x, column=2).value\n",
    "    HBO_movies.append([sheet.cell(row=x, column=2).value, 'HBO'])\n",
    "\n",
    "\n",
    "HBO_df = pd.DataFrame(data = HBO_movies, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rotten tomatoes, added for more recent list of movies\n",
    "tomatoes_movies = []\n",
    "\n",
    "#left second value in list empty because rotten tomatoes not streaming service\n",
    "tomatoes = openpyxl.load_workbook('movie_metadata.xlsx')\n",
    "sheet = tomatoes.get_sheet_by_name('sheet1')\n",
    "for x in range(2,5045):\n",
    "    tomatoes_movies.append([sheet.cell(row=x, column=12).value, ''])\n",
    "    \n",
    "for x in tomatoes_movies:\n",
    "    for y in x:\n",
    "        if y in ['c', 'd' ]:\n",
    "            x = x.replace(y, \"\")\n",
    "    \n",
    "tomatoes_df = pd.DataFrame(data = tomatoes_movies, columns = ['title', 'service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create list of all of the streaming services' dataframes + rotten tomatoes\n",
    "services = [HBO_df, showtime_df, amazon_df, netflix_df, hulu_df, tomatoes_df]\n",
    "\n",
    "#concatanate dataframes in large dataframe 'Movies_services'\n",
    "Movies_services = pd.concat(services)\n",
    "\n",
    "#clean dataframe, create 'year' column\n",
    "Movies_services['year'] = Movies_services['title'].str.extract('(\\d\\d\\d\\d)', expand=True)\n",
    "Movies_services['title'] = Movies_services['title'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "Movies_services['title'] = Movies_services['title'].str.replace(\" \",\"+\")\n",
    "length = len(Movies_services)\n",
    "Movies_services['movieId'] = [x for x in range(140000, (140000 + length))]\n",
    "\n",
    "Movies_services['api'] = Movies_services['title'] + '&y='\n",
    "Movies_services['api-year'] = Movies_services['title'] + '&y='\n",
    "\n",
    "#pickle Movies_services\n",
    "import pickle\n",
    "with open('Movies_services.pkl', 'w') as picklefile:\n",
    "    pickle.dump(Movies_services, picklefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/tools/merge.py:714: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  rlab = rizer.factorize(rk)\n"
     ]
    }
   ],
   "source": [
    "#open up pickled dataframe\n",
    "with open('Movies_services.pkl', 'r') as picklefile:\n",
    "    Movies_services = pickle.load(picklefile)\n",
    "\n",
    "#outer merge Movie_list and Movie_services dataframes, final list of movies\n",
    "Complete_df = pd.merge(Movie_list, Movies_services, how='outer')\n",
    "\n",
    "#pickle complete dataframe\n",
    "with open('complete_df.pkl', 'w') as picklefile:\n",
    "    pickle.dump(Complete_df, picklefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list of column names from one dictionary of data\n",
    "#testing api\n",
    "\n",
    "attributes = []\n",
    "\n",
    "from urllib2 import urlopen\n",
    "\n",
    "movies = urlopen(\"http://www.omdbapi.com/?t=Catwalk&y=&plot=short&r=json&tomatoes=true\")\n",
    "response = movies.read()\n",
    "\n",
    "#convert to dictionary\n",
    "response_dict = eval(response)\n",
    "\n",
    "#append each key in dictionary to a list, will be our model features\n",
    "for key in response_dict.keys():\n",
    "    attributes.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extremely slow way to populate dataframe with info from api\n",
    "\n",
    "#for attribute in attributes:\n",
    "    #name = attribute\n",
    "    #attribute = []\n",
    "    #for item, row in abr_df.iterrows():\n",
    "        #try:\n",
    "            #api = row['api']\n",
    "            #movies = urlopen(\"http://www.omdbapi.com/?t={}&plot=short&r=json&tomatoes=true\".format(api))\n",
    "            #results = movies.read()\n",
    "            #response_dict = eval(results)\n",
    "            #place_hold = response_dict[name]\n",
    "            #attribute.append(place_hold)\n",
    "        #except:\n",
    "            #attribute.append(None)\n",
    "            #pass\n",
    "    #abr_df[name] = attribute\n",
    "#abr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#populate final dataframe with api\n",
    "\n",
    "with open('complete_df.pkl', 'r') as picklefile:\n",
    "    Complete_df = pickle.load(picklefile)\n",
    "\n",
    "#define function that will be applied to every row in the database\n",
    "def pop_df(data):\n",
    "    #initiate empty lists that will each be populated as we cycle through rows in dataframe\n",
    "    Plot = []\n",
    "    Rated = []\n",
    "    Language = []\n",
    "    Title = []\n",
    "    Country = []\n",
    "    tomatoMeter = []\n",
    "    Writer = []\n",
    "    tomatoURL = []\n",
    "    BoxOffice = []\n",
    "    tomatoUserRating = []\n",
    "    Production = []\n",
    "    Actors = []\n",
    "    tomatoFresh = []\n",
    "    Runtime = []\n",
    "    Type = []\n",
    "    imdbVotes = []\n",
    "    Website = []\n",
    "    tomatoConsensus = []\n",
    "    tomatoReviews = []\n",
    "    tomatoImage = []\n",
    "    Poster = []\n",
    "    tomatoRotten = []\n",
    "    Metascore = []\n",
    "    Response = []\n",
    "    Director = []\n",
    "    Released = []\n",
    "    tomatoUserReviews = []\n",
    "    Awards = []\n",
    "    tomatoRating = []\n",
    "    Year = []\n",
    "    Genre = []\n",
    "    tomatoUserMeter = []\n",
    "    DVD = []\n",
    "    imdbRating = []\n",
    "    imdbID = []\n",
    "    for item, row in data.iterrows():\n",
    "        #iterate through rows in dataframe\n",
    "        try:    \n",
    "            #set api to value in 'api-year' column with was formated to be directly entered\n",
    "            #into imdb api\n",
    "            api = row['api-year']   #pass 'api' variable into url\n",
    "            movies = urlopen(\"http://www.omdbapi.com/?t={}&plot=short&r=json&tomatoes=true\".format(api))\n",
    "            results = movies.read()   #create dictionary of the results\n",
    "            response_dict = eval(results)\n",
    "            response = []   #create empty list\n",
    "            for key in response_dict.keys():   #append keys to response dictionary\n",
    "                response.append(key)\n",
    "            if set(response) != set(attributes):   #make sure movie has all features\n",
    "                try:   #if it doesn't try using api w/o year (sometimes year incorrect and throws off api)\n",
    "                    api = row['api']\n",
    "                    movies = urlopen(\"http://www.omdbapi.com/?t={}&plot=short&r=json&tomatoes=true\".format(api))\n",
    "                    results = movies.read()\n",
    "                    response_dict = eval(results)\n",
    "                    response = []\n",
    "                    for key in response_dict.keys():\n",
    "                        response.append(key)\n",
    "                    if set(response) >= set(attributes):   #if api works w/o year, append value in dictionary\n",
    "                                                           #whose key corresponds to list\n",
    "                        rated = response_dict['Rated']\n",
    "                        Rated.append(rated)\n",
    "                        plot = response_dict['Plot']\n",
    "                        Plot.append(plot)\n",
    "                        language = response_dict['Language']\n",
    "                        Language.append(language)\n",
    "                        title = response_dict['Title']\n",
    "                        Title.append(title)\n",
    "                        country = response_dict['Country']\n",
    "                        Country.append(country)\n",
    "                        tm = response_dict['tomatoMeter']\n",
    "                        tomatoMeter.append(tm)\n",
    "                        wr = response_dict['Writer']\n",
    "                        Writer.append(wr)\n",
    "                        turl = response_dict['tomatoURL']\n",
    "                        tomatoURL.append(turl)\n",
    "                        BO = response_dict['BoxOffice']\n",
    "                        BoxOffice.append(BO)\n",
    "                        tUR = response_dict['tomatoUserRating']\n",
    "                        tomatoUserRating.append(tUR)\n",
    "                        pro = response_dict['Production']\n",
    "                        Production.append(pro)\n",
    "                        act = response_dict['Actors']\n",
    "                        Actors.append(act)\n",
    "                        tf = response_dict['tomatoFresh']\n",
    "                        tomatoFresh.append(tf)\n",
    "                        rt = response_dict['Runtime']\n",
    "                        Runtime.append(rt)\n",
    "                        ty = response_dict['Type']\n",
    "                        Type.append(ty)\n",
    "                        imdbV = response_dict['imdbVotes']\n",
    "                        imdbVotes.append(imdbV)\n",
    "                        tomC = response_dict['tomatoConsensus']\n",
    "                        tomatoConsensus.append(tomC)\n",
    "                        tomR = response_dict['tomatoReviews']\n",
    "                        tomatoReviews.append(tomR)\n",
    "                        tomI = response_dict['tomatoImage']\n",
    "                        tomatoImage.append(tomI)\n",
    "                        post = response_dict['Poster']\n",
    "                        Poster.append(post)\n",
    "                        tomRot = response_dict['tomatoRotten']\n",
    "                        tomatoRotten.append(tomRot)\n",
    "                        meta = response_dict['Metascore']\n",
    "                        Metascore.append(meta)\n",
    "                        resp = response_dict['Response']\n",
    "                        Response.append(resp)\n",
    "                        dire = response_dict['Director']\n",
    "                        Director.append(dire)\n",
    "                        rele = response_dict['Released']\n",
    "                        Released.append(rele)\n",
    "                        tomURev = response_dict['tomatoUserReviews']\n",
    "                        tomatoUserReviews.append(tomURev)\n",
    "                        aw = response_dict['Awards']\n",
    "                        Awards.append(aw)\n",
    "                        tomRat = response_dict['tomatoRating']\n",
    "                        tomatoRating.append(tomRat)\n",
    "                        year = response_dict['Year']\n",
    "                        Year.append(year)\n",
    "                        gen = response_dict['Genre']\n",
    "                        Genre.append(gen)\n",
    "                        tomUM = response_dict['tomatoUserMeter']\n",
    "                        tomatoUserMeter.append(tomUM)\n",
    "                        dvd = response_dict['DVD']\n",
    "                        DVD.append(dvd)\n",
    "                        imdbRat = response_dict['imdbRating']\n",
    "                        imdbRating.append(imdbRat)\n",
    "                        imid = response_dict['imdbID']\n",
    "                        imdbID.append(imid)\n",
    "                        web = response_dict['Website']\n",
    "                        Website.append(web)\n",
    "                    else:   #otherwise append Null value to all of the columns, to maintain equal lists\n",
    "                        Plot.append(None)\n",
    "                        Rated.append(None)\n",
    "                        Language.append(None)\n",
    "                        Title.append(None)\n",
    "                        Country.append(None)\n",
    "                        tomatoMeter.append(None)\n",
    "                        Writer.append(None)\n",
    "                        tomatoURL.append(None)\n",
    "                        BoxOffice.append(None)\n",
    "                        tomatoUserRating.append(None)\n",
    "                        Production.append(None)\n",
    "                        Actors.append(None)\n",
    "                        tomatoFresh.append(None)\n",
    "                        Runtime.append(None)\n",
    "                        Type.append(None)\n",
    "                        imdbVotes.append(None)\n",
    "                        Website.append(None)\n",
    "                        tomatoConsensus.append(None)\n",
    "                        tomatoReviews.append(None)\n",
    "                        tomatoImage.append(None)\n",
    "                        Poster.append(None)\n",
    "                        tomatoRotten.append(None)\n",
    "                        Metascore.append(None)\n",
    "                        Response.append(None)\n",
    "                        Director.append(None)\n",
    "                        Released.append(None)\n",
    "                        tomatoUserReviews.append(None)\n",
    "                        Awards.append(None)\n",
    "                        tomatoRating.append(None)\n",
    "                        Year.append(None)\n",
    "                        Genre.append(None)\n",
    "                        tomatoUserMeter.append(None)\n",
    "                        DVD.append(None)\n",
    "                        imdbRating.append(None)\n",
    "                        imdbID.append(None)\n",
    "                except:\n",
    "                    Plot.append(None)\n",
    "                    Rated.append(None)\n",
    "                    Language.append(None)\n",
    "                    Title.append(None)\n",
    "                    Country.append(None)\n",
    "                    tomatoMeter.append(None)\n",
    "                    Writer.append(None)\n",
    "                    tomatoURL.append(None)\n",
    "                    BoxOffice.append(None)\n",
    "                    tomatoUserRating.append(None)\n",
    "                    Production.append(None)\n",
    "                    Actors.append(None)\n",
    "                    tomatoFresh.append(None)\n",
    "                    Runtime.append(None)\n",
    "                    Type.append(None)\n",
    "                    imdbVotes.append(None)\n",
    "                    Website.append(None)\n",
    "                    tomatoConsensus.append(None)\n",
    "                    tomatoReviews.append(None)\n",
    "                    tomatoImage.append(None)\n",
    "                    Poster.append(None)\n",
    "                    tomatoRotten.append(None)\n",
    "                    Metascore.append(None)\n",
    "                    Response.append(None)\n",
    "                    Director.append(None)\n",
    "                    Released.append(None)\n",
    "                    tomatoUserReviews.append(None)\n",
    "                    Awards.append(None)\n",
    "                    tomatoRating.append(None)\n",
    "                    Year.append(None)\n",
    "                    Genre.append(None)\n",
    "                    tomatoUserMeter.append(None)\n",
    "                    DVD.append(None)\n",
    "                    imdbRating.append(None)\n",
    "                    imdbID.append(None)\n",
    "            else:\n",
    "                rated = response_dict['Rated']\n",
    "                Rated.append(rated)\n",
    "                plot = response_dict['Plot']\n",
    "                Plot.append(plot)\n",
    "                language = response_dict['Language']\n",
    "                Language.append(language)\n",
    "                title = response_dict['Title']\n",
    "                Title.append(title)\n",
    "                country = response_dict['Country']\n",
    "                Country.append(country)\n",
    "                tm = response_dict['tomatoMeter']\n",
    "                tomatoMeter.append(tm)\n",
    "                wr = response_dict['Writer']\n",
    "                Writer.append(wr)\n",
    "                turl = response_dict['tomatoURL']\n",
    "                tomatoURL.append(turl)\n",
    "                BO = response_dict['BoxOffice']\n",
    "                BoxOffice.append(BO)\n",
    "                tUR = response_dict['tomatoUserRating']\n",
    "                tomatoUserRating.append(tUR)\n",
    "                pro = response_dict['Production']\n",
    "                Production.append(pro)\n",
    "                act = response_dict['Actors']\n",
    "                Actors.append(act)\n",
    "                tf = response_dict['tomatoFresh']\n",
    "                tomatoFresh.append(tf)\n",
    "                rt = response_dict['Runtime']\n",
    "                Runtime.append(rt)\n",
    "                ty = response_dict['Type']\n",
    "                Type.append(ty)\n",
    "                imdbV = response_dict['imdbVotes']\n",
    "                imdbVotes.append(imdbV)\n",
    "                tomC = response_dict['tomatoConsensus']\n",
    "                tomatoConsensus.append(tomC)\n",
    "                tomR = response_dict['tomatoReviews']\n",
    "                tomatoReviews.append(tomR)\n",
    "                tomI = response_dict['tomatoImage']\n",
    "                tomatoImage.append(tomI)\n",
    "                post = response_dict['Poster']\n",
    "                Poster.append(post)\n",
    "                tomRot = response_dict['tomatoRotten']\n",
    "                tomatoRotten.append(tomRot)\n",
    "                meta = response_dict['Metascore']\n",
    "                Metascore.append(meta)\n",
    "                resp = response_dict['Response']\n",
    "                Response.append(resp)\n",
    "                dire = response_dict['Director']\n",
    "                Director.append(dire)\n",
    "                rele = response_dict['Released']\n",
    "                Released.append(rele)\n",
    "                tomURev = response_dict['tomatoUserReviews']\n",
    "                tomatoUserReviews.append(tomURev)\n",
    "                aw = response_dict['Awards']\n",
    "                Awards.append(aw)\n",
    "                tomRat = response_dict['tomatoRating']\n",
    "                tomatoRating.append(tomRat)\n",
    "                year = response_dict['Year']\n",
    "                Year.append(year)\n",
    "                gen = response_dict['Genre']\n",
    "                Genre.append(gen)\n",
    "                tomUM = response_dict['tomatoUserMeter']\n",
    "                tomatoUserMeter.append(tomUM)\n",
    "                dvd = response_dict['DVD']\n",
    "                DVD.append(dvd)\n",
    "                imdbRat = response_dict['imdbRating']\n",
    "                imdbRating.append(imdbRat)\n",
    "                imid = response_dict['imdbID']\n",
    "                imdbID.append(imid)\n",
    "                web = response_dict['Website']\n",
    "                Website.append(web)\n",
    "        except:\n",
    "            x = row['api']\n",
    "            print x + '4' \n",
    "            Plot.append(None)\n",
    "            Rated.append(None)\n",
    "            Language.append(None)\n",
    "            Title.append(None)\n",
    "            Country.append(None)\n",
    "            tomatoMeter.append(None)\n",
    "            Writer.append(None)\n",
    "            tomatoURL.append(None)\n",
    "            BoxOffice.append(None)\n",
    "            tomatoUserRating.append(None)\n",
    "            Production.append(None)\n",
    "            Actors.append(None)\n",
    "            tomatoFresh.append(None)\n",
    "            Runtime.append(None)\n",
    "            Type.append(None)\n",
    "            imdbVotes.append(None)\n",
    "            Website.append(None)\n",
    "            tomatoConsensus.append(None)\n",
    "            tomatoReviews.append(None)\n",
    "            tomatoImage.append(None)\n",
    "            Poster.append(None)\n",
    "            tomatoRotten.append(None)\n",
    "            Metascore.append(None)\n",
    "            Response.append(None)\n",
    "            Director.append(None)\n",
    "            Released.append(None)\n",
    "            tomatoUserReviews.append(None)\n",
    "            Awards.append(None)\n",
    "            tomatoRating.append(None)\n",
    "            Year.append(None)\n",
    "            Genre.append(None)\n",
    "            tomatoUserMeter.append(None)\n",
    "            DVD.append(None)\n",
    "            imdbRating.append(None)\n",
    "            imdbID.append(None)\n",
    "    data['Plot'] = Plot\n",
    "    data['Rated'] = Rated\n",
    "    data['Language'] = Language\n",
    "    data['Title'] = Title\n",
    "    data['Country'] = Country\n",
    "    data['tomatoMeter'] = tomatoMeter\n",
    "    data['Writer'] = Writer\n",
    "    data['tomatoURL'] = tomatoURL\n",
    "    data['BoxOffice'] = BoxOffice\n",
    "    data['tomatoUserRating'] = tomatoUserRating\n",
    "    data['Production'] = Production\n",
    "    data['Actors'] = Actors\n",
    "    data['tomatoFresh'] = tomatoFresh\n",
    "    data['Runtime'] = Runtime\n",
    "    data['Type'] = Type\n",
    "    data['imdbVotes'] = imdbVotes\n",
    "    data['Website'] = Website\n",
    "    data['tomatoConsensus'] = tomatoConsensus\n",
    "    data['tomatoReviews'] = tomatoReviews\n",
    "    data['tomatoImage'] = tomatoImage\n",
    "    data['Poster'] = Poster\n",
    "    data['tomatoRotten'] = tomatoRotten\n",
    "    data['Metascore'] = Metascore\n",
    "    data['Response'] = Response\n",
    "    data['Director'] = Director\n",
    "    data['Released'] = Released\n",
    "    data['tomatoUserReviews'] = tomatoUserReviews\n",
    "    data['Awards'] = Awards\n",
    "    data['tomatoRating '] = tomatoRating \n",
    "    data['Year'] = Year\n",
    "    data['Genre'] = Genre\n",
    "    data['tomatoUserMeter'] = tomatoUserMeter\n",
    "    data['DVD'] = DVD\n",
    "    data['imdbRating'] = imdbRating\n",
    "    data['imdbID'] = imdbID\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#with open('finalMovie1_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie1_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finalMovie2_df = pop_df(Complete_df[10000:20000])\n",
    "#finalMovie2_df\n",
    "\n",
    "#with open('finalMovie2_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie2_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finalMovie3_df = pop_df(Complete_df[20000:25000])\n",
    "#finalMovie3_df\n",
    "\n",
    "#with open('finalMovie3_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie3_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finalMovie4_df = pop_df(Complete_df[25000:30000])\n",
    "#finalMovie4_df\n",
    "\n",
    "#with open('finalMovie4_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie4_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finalMovie5_df = pop_df(Complete_df[30000:35000])\n",
    "#finalMovie5_df\n",
    "\n",
    "#with open('finalMovie5_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie5_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finalMovie6_df = pop_df(Complete_df[35000:39900])\n",
    "#finalMovie6_df\n",
    "\n",
    "#with open('finalMovie6_df.pkl', 'w') as picklefile:\n",
    "    #pickle.dump(finalMovie6_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read all of the pickled dataframes\n",
    "\n",
    "with open('finalMovie1_df.pkl', 'r') as picklefile:\n",
    "    finalMovie1_df = pickle.load(picklefile)\n",
    "with open('finalMovie2_df.pkl', 'r') as picklefile:\n",
    "    finalMovie2_df = pickle.load(picklefile)\n",
    "with open('finalMovie3_df.pkl', 'r') as picklefile:\n",
    "    finalMovie3_df = pickle.load(picklefile)\n",
    "with open('finalMovie4_df.pkl', 'r') as picklefile:\n",
    "    finalMovie4_df = pickle.load(picklefile)\n",
    "with open('finalMovie5_df.pkl', 'r') as picklefile:\n",
    "    finalMovie5_df = pickle.load(picklefile)\n",
    "with open('finalMovie6_df.pkl', 'r') as picklefile:\n",
    "    finalMovie6_df = pickle.load(picklefile)\n",
    "\n",
    "#list of populated dataframes\n",
    "frames = [finalMovie2_df, finalMovie3_df, finalMovie4_df, finalMovie5_df, finalMovie6_df]\n",
    "\n",
    "#append list of dataframes to the first one\n",
    "FinalMovie_df = finalMovie1_df.append(frames)\n",
    "\n",
    "#delete movies that were not found in IMDB, revisit later to have better retention\n",
    "FinalMovie_df = FinalMovie_df[FinalMovie_df.imdbID.notnull()]\n",
    "\n",
    "#drop unnecessary columns\n",
    "FinalMovie_df.drop('title', axis=1, inplace= True)\n",
    "FinalMovie_df.drop('genres', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('year', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('api-year', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('api', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create functions that create new column for each service and categorize each movie\n",
    "#1 or 0 if movie found on that service\n",
    "def netflixcol(x):\n",
    "    if x == 'netflix':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def hulucol(x):\n",
    "    if x == 'hulu':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def hbocol(x):\n",
    "    if x == 'hbo':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def showcol(x):\n",
    "    if x == 'showtime':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def amazoncol(x):\n",
    "    if x == 'amazon':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#apply functions to the 'service' column and then delete it\n",
    "FinalMovie_df['netflix'] = FinalMovie_df['service'].apply(netflixcol)\n",
    "FinalMovie_df['hulu'] = FinalMovie_df['service'].apply(hulucol)\n",
    "FinalMovie_df['hbo'] = FinalMovie_df['service'].apply(hbocol)\n",
    "FinalMovie_df['showtime'] = FinalMovie_df['service'].apply(showcol)\n",
    "FinalMovie_df['amazon'] = FinalMovie_df['service'].apply(amazoncol)\n",
    "\n",
    "FinalMovie_df.drop('service', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now check for duplicate movies across different services and if duplicate merge the service\n",
    "#columns\n",
    "\n",
    "servicegrid_df = FinalMovie_df.groupby('Title')['netflix', 'hulu', 'hbo', 'showtime', 'amazon'].sum()\n",
    "servicegrid_df = servicegrid_df.reset_index()\n",
    "\n",
    "FinalMovie_df = FinalMovie_df.drop_duplicates('Title')\n",
    "\n",
    "FinalMovie_df.drop('netflix', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('hulu', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('hbo', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('showtime', axis=1, inplace=True)\n",
    "FinalMovie_df.drop('amazon', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final movie dataframe with duplicates removed\n",
    "FinalMovie_df = pd.merge(FinalMovie_df, servicegrid_df)\n",
    "\n",
    "with open('FinalMovie_df.pkl', 'w') as picklefile:\n",
    "    pickle.dump(FinalMovie_df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#option to export to SQL, needed to be normalized and null values populated\n",
    "\n",
    "#engine = create_engine('postgresql://KMS@localhost:5432/Capstone')\n",
    "#*df*.to_sql('*df*(name of table)', engine)\n",
    "\n",
    "# And you are done! You can now go to psql and explore your database and tables there. \n",
    "#If you want to import the data from the postgres database to python/pandas, see code below:\n",
    "\n",
    "#%load_ext sql\n",
    "#%%sql postgresql://KMS@localhost:5432/Capstone\n",
    "        \n",
    "#SELECT * FROM *df* LIMIT 5;\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
